<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Thomas Lumley" />

<meta name="date" content="2023-03-30" />

<title>VGAMs for survey data: theory</title>


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>







<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />




</head>

<body>




<h1 class="title toc-ignore">VGAMs for survey data: theory</h1>
<h4 class="author">Thomas Lumley</h4>
<h4 class="date">2023-03-30</h4>



<p>The <strong>VGAM</strong> package's <code>vglm()</code> function, like the <strong>survey</strong> package's <code>svymle()</code> function, allows for maximum likelihood fitting where linear predictors are added to one or more parameters of a distribution --- but <code>vglm()</code> is a lot faster and has many distributions already built in. This is how we make <strong>svyVGAM</strong> handle complex sampling.</p>
<p>I will write <span class="math inline">\(\beta\)</span> for the regression parameters, <span class="math inline">\(\theta\)</span> for the base parameters of the response distribution, and <span class="math inline">\(\eta\)</span> for the linear predictors. So, for example, in a classical linear model there would be two parameters <span class="math inline">\(\theta\)</span>: the mean (<span class="math inline">\(\theta_1\)</span>) and variance (<span class="math inline">\(\theta_2\)</span>). The mean would have a set of regression parameters and the variance would have a single parameter. Collectively, these would be <span class="math inline">\(\beta\)</span> (maybe <span class="math inline">\(\beta_{11}\dots\beta_{1p}\)</span> and <span class="math inline">\(\beta_{21}\)</span>), and the two combinations that are plugged in as <span class="math inline">\(\theta\)</span> would be called <span class="math inline">\(\eta_1\)</span> and <span class="math inline">\(\eta_2\)</span>. The big advantage of <strong>VGAM</strong> is that it does a lot of the work for the user: while the user can add new families, there are many pre-prepared ones, and there are built-in ways to constrain parameters to be equal or related in some other way.</p>
<p>To provide survey versions of <code>vglm()</code>, we need to (a) get design-consistent point estimates out of <code>vglm()</code>, and (b) construct design-based standard errors for the fit. The first is easy: <code>vglm()</code> accepts frequency weights, which are <a href="https://notstatschat.rbind.io/2020/08/04/weights-in-statistics/">equivalent to sampling weights for point estimation</a> with independent observations.</p>
<p>The second can be done in two ways: resampling (which is straightforward, if potentially slow), and linearisation. Linearisation requires computing the influence functions of the parameters <span class="math display">\[h_i(\beta) = -\widehat{\cal I}^{-1}_w U_i(\beta)\]</span> where <span class="math inline">\(\widehat{\cal I}_w\)</span> is the weighted estimate of the population Fisher information, <span class="math inline">\(U_i=\partial_\beta \ell_i(\beta)\)</span> is the loglikelihood contribution of the <span class="math inline">\(i\)</span>th observation, and <span class="math inline">\(w_i\)</span> is its weight. The influence functions have the property <span class="math display">\[\hat\beta-\beta_0 = \sum_i w_i h_i(\beta_0)+o_p(\|\hat\beta-\beta_0\|)\]</span> so that the variance of <span class="math inline">\(\hat\beta\)</span> is asymptotically the variance of the population total of the influence functions. The survey package provides a function <code>svyrecvar()</code> to estimate standard errors given the influence functions, or (a bit less efficiently) you can just call <code>svytotal()</code>.</p>
<div id="resampling" class="section level3">
<h3>Resampling</h3>
<p>A design object of class <code>svyrep.design</code> contains sets of replicate weights analogous to jackknife or bootstrap replicates. We need to call <code>vglm()</code> with each set of weights. It should be helpful to specify the full-sample estimates as starting values.</p>
<p>One complication is that sets of replicate weights will typically include some zeroes, which <code>vglm()</code> does not allow (eg, a bootstrap or jackknife resample will omit some observations). We set these to <span class="math inline">\(10^{-9}\)</span> times the maximum weight, which has the desired effect that the observations are present in the fit but with (effectively) zero weight.</p>
</div>
<div id="linearisation" class="section level3">
<h3>Linearisation</h3>
<p>The <code>cov.unscaled</code> slot of a <code>summary.vglm</code> object contains the inverse of the estimated population Fisher information, <span class="math inline">\(\widehat{\cal I}^{-1}_w\)</span>.</p>
<p>The <code>vglm</code> object provides <span class="math inline">\(\partial_\eta\ell_i(\eta)\)</span> for the base parameters <span class="math inline">\(\theta\)</span>, and also the model matrices that specify <span class="math inline">\(\partial_\beta\eta\)</span>, so we can construct <span class="math inline">\(U_i\)</span>. We need to take care with the constraints, which can cause a coefficient <span class="math inline">\(\beta\)</span> to appear in more than one linear predictor.</p>
<p>Suppose <span class="math inline">\(\beta_x\)</span> appears in both <span class="math inline">\(\eta_1\)</span> and <span class="math inline">\(\eta_2\)</span>, with <span class="math inline">\(x\)</span> values <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. The chain rule tells us <span class="math display">\[\partial_{\beta_x}\ell_i =\partial_{\eta_1}\ell_i\partial_{\beta_x}\eta_1 + \partial_{\eta_2}\ell_i\partial_{\beta_x}\eta_2 = (\partial_{\eta_1}\ell_i) x_{1i}+ (\partial_{\eta_2}\ell_i) x_{2i} \]</span> We might have <span class="math inline">\(x_1\equiv x_2\,(=x)\)</span>, but that just means <span class="math display">\[\partial_{\beta_x}\ell_i = (\partial_{\eta_1}\ell_i) x_{i}+ (\partial_{\eta_2}\ell_i) x_{i} \]</span></p>
<p>The constraint matrix <span class="math inline">\(C\)</span> consists of 1s and 0s. If there are <span class="math inline">\(p\)</span> parameters in <span class="math inline">\(M\)</span> equations the matrix is <span class="math inline">\(M\times p\)</span>, with <span class="math inline">\(C_{jk}=1\)</span> if parameter <span class="math inline">\(k\)</span> is in linear predictor <span class="math inline">\(j\)</span>. In the default, unconstrained setup, the constraint matrix consists of an <span class="math inline">\(M\times M\)</span> identity matrix for each parameter, pasted columnwise to give a <span class="math inline">\(M\times pM\)</span> matrix. In the proportional odds model, as another example, there are separate intercepts for each linear predictor but the other parameters all appear in every linear predictor. The first <span class="math inline">\(M\times M\)</span> block is the identity, and the rest of the matrix is a column of 1s for each predictor variable. Another way to say this is that <span class="math inline">\(C_{jk}=\partial_{ (\beta_kx_k)}\eta_j\)</span></p>
So, if we want <span class="math inline">\(\partial\beta\ell_i\)</span>, the chain rule says
<span class="math display">\[\begin{eqnarray*}
\frac{\partial \ell_i}{\partial \beta_j} &amp;=&amp; \sum_k\frac{\partial \ell_i}{\partial\eta_k} \frac{\partial \eta_k}{\partial \beta_j}\\
&amp;=&amp; \sum_k\frac{\partial \ell_i}{\partial \eta_k} \frac{\partial \eta_k}{\partial (x\beta)_j}\frac{\partial (x\beta)_j}{\partial \beta_j}\\
&amp;=&amp;\sum_k \frac{\partial \ell_i}{\partial \eta_k}  C_{kj}x_{ij}
\end{eqnarray*}\]</span>
<p>There is one further complication. The <code>model.matrix</code> method for <code>vglm</code> objects returns a model matrix of dimension <span class="math inline">\(Mn\times p\)</span> rather than <span class="math inline">\(n\times p\)</span>, so we need to sum over the rows for each observation, which can be identified from the row names, and then rescale. The right standardisation appears to come from defining <span class="math display">\[\tilde C_{kj}=\frac{C_{kj}}{\sum_k C_{kj}}\]</span> and then <span class="math display">\[\frac{\partial \ell_i}{\partial \beta_j}=\sum_k \frac{\partial \ell_i}{\partial \eta_k}  \tilde C_{kj}x_{ikj}.\]</span></p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
